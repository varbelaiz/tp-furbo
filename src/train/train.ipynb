{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da90925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aaae074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n",
      "Sun Nov 23 14:15:12 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-SXM2-16GB           On  |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P0             24W /  300W |       3MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "if cuda_available:\n",
    "\n",
    "  print(\"CUDA is available\")\n",
    "  !nvidia-smi\n",
    "\n",
    "else:\n",
    "\n",
    "  message = \"\"\"\n",
    "    WARNING: In order to train the model, it is advisable to use GPU.\n",
    "    Change runtime type to GPU from:\n",
    "      menu Runtime -> Change runtime type -> Hardware accelerator -> GPU.\n",
    "      And run all the cells again.\n",
    "  \"\"\"\n",
    "  print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f56cc96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.9.1+cu128 CUDA runtime: 12.8\n",
      "Tesla V100-SXM2-16GB\n",
      "Capability: (7, 0)\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch:\", torch.__version__, \"CUDA runtime:\", torch.version.cuda)\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(\"Capability:\", torch.cuda.get_device_capability(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a0905f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialized_model_file(\n",
    "    checkpoint=\"best\",\n",
    "    use_run=\"train\",\n",
    "):\n",
    "  \"\"\"\n",
    "    Returns the serialized file path.\n",
    "  \"\"\"\n",
    "  return f\"runs/detect/{use_run}/weights/{checkpoint}.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601408f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH = 4\n",
    "IMG_SIZE = 1080\n",
    "FALLBACK = \"yolo11x.pt\"\n",
    "FRACTION = 0.4\n",
    "\n",
    "def train(\n",
    "    data,\n",
    "    use_run=\"train\",\n",
    "    fallback=FALLBACK,\n",
    "    epochs=EPOCHS,\n",
    "    augment=True,\n",
    "  ):\n",
    "\n",
    "  cuda_available = torch.cuda.is_available()\n",
    "\n",
    "  if not cuda_available:\n",
    "    print(\"Warning CUDA is not available, train would take too much time.\")\n",
    "    # return\n",
    "\n",
    "  if cuda_available:\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  model_file = serialized_model_file(\"last\", use_run)\n",
    "\n",
    "  if os.path.exists(model_file):\n",
    "    resume_training = True\n",
    "    use_model = model_file\n",
    "    \n",
    "  else:\n",
    "    resume_training = False\n",
    "    use_model = fallback\n",
    "\n",
    "  model = YOLO(\n",
    "      use_model\n",
    "  )\n",
    "\n",
    "  model.train(\n",
    "      data = data,\n",
    "      resume = resume_training,\n",
    "      epochs = epochs,\n",
    "      device = 'cuda',\n",
    "      optimizer=\"AdamW\",\n",
    "      time=10,\n",
    "      # lr0=0.0001,\n",
    "      imgsz = IMG_SIZE,\n",
    "      batch = BATCH,\n",
    "      augment = augment,\n",
    "      amp = True,\n",
    "      fraction = FRACTION\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee79dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.230 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.228 ðŸš€ Python-3.13.9 torch-2.9.1+cu128 CUDA:0 (Tesla V100-SXM2-16GB, 16144MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data/tracking/YOLO/tracker.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=0.4, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1080, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11x.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train4, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/valen/tp-furbo/runs/detect/train4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=8, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
      "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
      "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
      "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  9                  -1  1   1476864  ultralytics.nn.modules.block.SPPF            [768, 768, 5]                 \n",
      " 10                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2   1700352  ultralytics.nn.modules.block.C3k2            [1536, 384, 2, True]          \n",
      " 17                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   5317632  ultralytics.nn.modules.block.C3k2            [1152, 768, 2, True]          \n",
      " 20                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
      " 23        [16, 19, 22]  1   3150172  ultralytics.nn.modules.head.Detect           [4, [384, 768, 768]]          \n",
      "YOLO11x summary: 357 layers, 56,878,396 parameters, 56,878,380 gradients, 195.5 GFLOPs\n",
      "\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    data=\"data/tracking/YOLO/tracker.yaml\",\n",
    "    use_run=None,\n",
    "    augment=True\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp-furbo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
